{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from lib.DataManager import *\n",
    "from lib.PolicyStats import *\n",
    "from lib.Gridworld import *\n",
    "from lib.Mockworld import *\n",
    "import os\n",
    "import cma\n",
    "from cma.constraints_handler import AugmentedLagrangian, PopulationEvaluator\n",
    "from IPython import display\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Set Params***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---SET PARAMS---\n",
    "USE_GRIDWORLD = False\n",
    "USE_PDIS = True\n",
    "percent_increase = 0.1\n",
    "num_policies = 50\n",
    "es_path = \"pickles/van/saved-cma-van-pdis-20.pkl\"\n",
    "gamma = 0.95\n",
    "delta = 0.01 #1 - delta, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Setup Environment***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = 18\n",
    "if(USE_GRIDWORLD):\n",
    "    print(\"Using Gridworld\")\n",
    "    num_states = 23\n",
    "num_actions = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line 0\n",
      "line 1000000\n",
      "line 2000000\n",
      "line 3000000\n",
      "line 4000000\n",
      "line 5000000\n",
      "line 6000000\n",
      "line 7000000\n",
      "line 8000000\n",
      "line 9000000\n",
      "line 10000000\n",
      "line 11000000\n",
      "line 12000000\n",
      "line 13000000\n",
      "line 14000000\n",
      "line 15000000\n",
      "line 16000000\n",
      "line 17000000\n",
      "line 18000000\n",
      "line 19000000\n",
      "line 20000000\n",
      "line 21000000\n",
      "line 22000000\n",
      "line 23000000\n",
      "line 24000000\n",
      "line 25000000\n",
      "line 26000000\n",
      "line 27000000\n",
      "line 28000000\n",
      "line 29000000\n",
      "line 30000000\n",
      "line 31000000\n",
      "line 32000000\n",
      "line 33000000\n",
      "line 34000000\n",
      "line 35000000\n",
      "line 36000000\n",
      "line 37000000\n",
      "line 38000000\n",
      "line 39000000\n",
      "line 40000000\n",
      "line 41000000\n",
      "line 42000000\n",
      "line 43000000\n",
      "line 44000000\n",
      "line 45000000\n",
      "line 46000000\n",
      "line 47000000\n",
      "line 48000000\n",
      "line 49000000\n",
      "line 50000000\n"
     ]
    }
   ],
   "source": [
    "path = \"data\\data.csv\"\n",
    "if(USE_GRIDWORLD):\n",
    "    path = \"data\\gridworld_data.csv\"\n",
    "\n",
    "histories = GetHistories(path, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = SplitData(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_exploratory_J = GetAverageReturn(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_performance = GetTargetPerformance(USE_GRIDWORLD, avg_exploratory_J, percent_increase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_policy = GetPolicy(train, num_states, num_actions, 1000)\n",
    "print(exploration_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISFunc = ImportanceSampling\n",
    "if(USE_PDIS):\n",
    "    ISFunc = PDImportanceSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = pickle.load(open(es_path, \"rb\"))\n",
    "print(\"ES_Convergence : \" + str(sum(es.mean**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_softmax(policy):\n",
    "    numerators = np.exp(policy)\n",
    "    return (numerators.T / np.sum(numerators, axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_returns = 0\n",
    "new_policy = None\n",
    "theoretical_fails = 0\n",
    "actual_fails = 0\n",
    "i = 0\n",
    "while i < num_policies:\n",
    "    passed_theoretical = False\n",
    "    try:\n",
    "        print(\"~x~~x~~~x~~~~~x~~~~~x~~~x~~~~~x~~~~x~~\")\n",
    "        print(i)\n",
    "        solution = es.ask(1)[0].reshape(num_states, num_actions)\n",
    "        new_policy = policy_softmax(solution)\n",
    "        ConfirmBounds(False, target_performance, train, test, exploration_policy, gamma, new_policy, ISFunc, delta)\n",
    "        passed_theoretical = True\n",
    "        #policy passes theoretic check\n",
    "\n",
    "        actual_J = -1\n",
    "        if(USE_GRIDWORLD):\n",
    "            actual_J = GetGridworldReturn(new_policy, gamma, 100000)\n",
    "        else:\n",
    "            actual_J = GetMockworldReturn(new_policy, gamma, 100000)\n",
    "\n",
    "        ConfirmBounds(True, actual_J, train, test, exploration_policy, gamma, new_policy, ISFunc, delta)\n",
    "        #policy passes actual check\n",
    "#         path = \"text_policies\\\\policy\" + str(i + 1) + \".txt\"\n",
    "#         WriteSolutionToTxt(path, solution)\n",
    "#         loaded_solution = LoadSolutionFromTxt(path, num_states, num_actions)\n",
    "#         assert np.sum(loaded_solution - solution) == 0\n",
    "        \n",
    "        avg_returns += actual_J\n",
    "        i += 1\n",
    "    except:\n",
    "        print(\"___F A I L___\")\n",
    "        if(passed_theoretical):\n",
    "            actual_fails += 1\n",
    "        else:\n",
    "            theoretical_fails += 1\n",
    "\n",
    "avg_returns /= num_policies\n",
    "print(\"Number of Actual Fails : \" + str(actual_fails))\n",
    "print(\"Number of Theoretical Fails : \" + str(theoretical_fails))\n",
    "print(\"Average Return : \" + str(avg_returns))\n",
    "print(\"Target : \" + str(target_performance))\n",
    "print(\"Confidence : \" + str(delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greed_policy = np.argmax(new_policy,axis=1)\n",
    "\n",
    "if(USE_GRIDWORLD):\n",
    "    print(np.insert(greed_policy, [12,16],[-1,-1]).reshape((5,5)))\n",
    "else:\n",
    "    print(greed_policy[-2:])\n",
    "    print(greed_policy[:-2].reshape(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
